Diora fork: 27/07/2021

Changes:
- train.py:
-- added argument --emb_default_size
-- changed --embeddings_path argument to take None as default
-- changed --emb argument to have also a (default) option of 'none', for the case when no pre-trained embeddings are used
- dataset.py:
added option to bypass embeddings in run
- embeddings.py:
-- made the allenlp elmo dependency local (as the library is not supported in later versions)
- batch_iterator.py:
-- try-catch around import of allenlp elmo library (as is not supported in later versions)
- trainer.py
-- create embeddings from vocabulary when no pre-trained embeddings are provided
- parse.py
-- create embeddings from vocabulary when no pre-trained embeddings are provided
